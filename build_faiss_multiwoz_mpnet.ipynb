{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fd5a7e-a813-4d00-a258-b23461961dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, Text, List\n",
    "\n",
    "\n",
    "class MultiWOZDatabase:\n",
    "    def __init__(self, database_path: str):\n",
    "        self.database_path = database_path\n",
    "        self.DOMAINS = [\n",
    "            'restaurant',\n",
    "            'hotel',\n",
    "            'attraction',\n",
    "            'train',\n",
    "            'taxi',\n",
    "            'police',\n",
    "            'hospital'\n",
    "        ]\n",
    "        self.database_data = {}\n",
    "        self.database_keys = {}\n",
    "        self._load_data()\n",
    "        self._print_structure_examples()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"加载数据库，并将字段名转为小写，提取所有字段 key。\"\"\"\n",
    "        for domain in self.DOMAINS:\n",
    "            file_path = os.path.join(self.database_path, f\"{domain}_db.json\")\n",
    "            with open(file_path, \"r\") as f:\n",
    "                self.database_data[domain] = json.load(f)\n",
    "\n",
    "            self.database_keys[domain] = set()\n",
    "\n",
    "            if domain == 'taxi':\n",
    "                # taxi 是 dict\n",
    "                self.database_data[domain] = {\n",
    "                    k.lower(): v for k, v in self.database_data[domain].items()\n",
    "                }\n",
    "                self.database_keys[domain].update(self.database_data[domain].keys())\n",
    "            else:\n",
    "                for i, item in enumerate(self.database_data[domain]):\n",
    "                    # 所有字段转为小写\n",
    "                    self.database_data[domain][i] = {\n",
    "                        k.lower(): v for k, v in item.items()\n",
    "                    }\n",
    "                    self.database_keys[domain].update(self.database_data[domain][i].keys())\n",
    "\n",
    "    def _print_structure_examples(self):\n",
    "        \"\"\"打印每个 domain 的示例数据和字段。\"\"\"\n",
    "        for domain in self.DOMAINS:\n",
    "            print(f\"=== {domain.upper()} ===\")\n",
    "            if domain == 'taxi':\n",
    "                print(\"Sample data (taxi domain is a dict):\")\n",
    "                for k, v in list(self.database_data[domain].items())[:1]:\n",
    "                    print(f\"{k}: {v}\")\n",
    "            else:\n",
    "                print(\"First item in data:\")\n",
    "                print(self.database_data[domain][0])\n",
    "\n",
    "            print(\"Extracted keys:\")\n",
    "            print(self.database_keys[domain])\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def query(self, domain: Text, constraints: Dict[Text, Text]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        返回指定 domain 中满足所有 constraints 的实体列表。\n",
    "\n",
    "        参数：\n",
    "            domain:      查询的领域名，如 'hotel'、'restaurant'。\n",
    "            constraints: 键值对形式的硬约束，如 {'area': 'north', 'parking': 'yes'}\n",
    "\n",
    "        返回：\n",
    "            满足条件的实体（字典）组成的列表\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        if domain not in self.database_data:\n",
    "            print(f\"[Warning] Domain '{domain}' not in database.\")\n",
    "            return results\n",
    "\n",
    "        entities = self.database_data[domain]\n",
    "\n",
    "        if domain == \"taxi\":\n",
    "            results = [entities]  # 直接返回所有\n",
    "        else:\n",
    "            for entity in entities:\n",
    "                match = True\n",
    "                for key, value in constraints.items():\n",
    "                    key = key.lower()\n",
    "                    entity_value = entity.get(key, \"\").lower()\n",
    "                    if isinstance(entity_value, list):\n",
    "                        if value.lower() not in [v.lower() for v in entity_value]:\n",
    "                            match = False\n",
    "                            break\n",
    "                    else:\n",
    "                        if value.lower() != entity_value:\n",
    "                            match = False\n",
    "                            break\n",
    "                if match:\n",
    "                    results.append(entity)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6151acb-acdd-45cb-b185-dff74eeb482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESTAURANT ===\n",
      "First item in data:\n",
      "{'address': 'Regent Street City Centre', 'area': 'centre', 'food': 'italian', 'id': '19210', 'introduction': 'Pizza hut is a large chain with restaurants nationwide offering convenience pizzas pasta and salads to eat in or take away', 'location': [52.20103, 0.126023], 'name': 'pizza hut city centre', 'phone': '01223323737', 'postcode': 'cb21ab', 'pricerange': 'cheap', 'type': 'restaurant'}\n",
      "Extracted keys:\n",
      "{'name', 'id', 'pricerange', 'area', 'introduction', 'signature', 'type', 'address', 'postcode', 'food', 'location', 'phone'}\n",
      "\n",
      "\n",
      "=== HOTEL ===\n",
      "First item in data:\n",
      "{'address': '124 tenison road', 'area': 'east', 'internet': 'yes', 'parking': 'no', 'id': '0', 'location': [52.1963733, 0.1987426], 'name': 'a and b guest house', 'phone': '01223315702', 'postcode': 'cb12dp', 'price': {'double': '70', 'family': '90', 'single': '50'}, 'pricerange': 'moderate', 'stars': '4', 'takesbookings': 'yes', 'type': 'guesthouse'}\n",
      "Extracted keys:\n",
      "{'parking', 'price', 'name', 'id', 'pricerange', 'stars', 'internet', 'area', 'type', 'address', 'postcode', 'takesbookings', 'location', 'phone'}\n",
      "\n",
      "\n",
      "=== ATTRACTION ===\n",
      "First item in data:\n",
      "{'address': 'pool way, whitehill road, off newmarket road', 'area': 'east', 'entrance fee': '?', 'id': '1', 'location': [52.208789, 0.154883], 'name': 'abbey pool and astroturf pitch', 'openhours': '?', 'phone': '01223902088', 'postcode': 'cb58nt', 'pricerange': '?', 'type': 'swimmingpool'}\n",
      "Extracted keys:\n",
      "{'entrance fee', 'openhours', 'name', 'id', 'pricerange', 'area', 'type', 'address', 'postcode', 'location', 'phone'}\n",
      "\n",
      "\n",
      "=== TRAIN ===\n",
      "First item in data:\n",
      "{'arriveby': '05:51', 'day': 'monday', 'departure': 'cambridge', 'destination': 'london kings cross', 'duration': '51 minutes', 'leaveat': '05:00', 'price': '23.60 pounds', 'trainid': 'TR7075'}\n",
      "Extracted keys:\n",
      "{'price', 'destination', 'departure', 'leaveat', 'day', 'arriveby', 'trainid', 'duration'}\n",
      "\n",
      "\n",
      "=== TAXI ===\n",
      "Sample data (taxi domain is a dict):\n",
      "taxi_colors: ['black', 'white', 'red', 'yellow', 'blue', 'grey']\n",
      "Extracted keys:\n",
      "{'taxi_phone', 'taxi_types', 'taxi_colors'}\n",
      "\n",
      "\n",
      "=== POLICE ===\n",
      "First item in data:\n",
      "{'name': 'Parkside Police Station', 'address': 'Parkside, Cambridge', 'id': 0, 'phone': '01223358966', 'postcode': 'CB11JG'}\n",
      "Extracted keys:\n",
      "{'name', 'id', 'postcode', 'address', 'phone'}\n",
      "\n",
      "\n",
      "=== HOSPITAL ===\n",
      "First item in data:\n",
      "{'department': 'neurosciences critical care unit', 'id': 0, 'phone': '01223216297'}\n",
      "Extracted keys:\n",
      "{'phone', 'department', 'id'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "database_path = \"./multiwoz_database\"\n",
    "database = MultiWOZDatabase(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588ebf57-28b4-4107-a802-1038e4227951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('multi_woz_v22')\n",
    "data = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e89dcb5-f59c-491e-87fa-77cebc4cc4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"page_content\": \"Customer: i need a place to dine in the center thats expensive\",\n",
      "  \"question\": \"i need a place to dine in the center thats expensive\",\n",
      "  \"gt_state\": {\n",
      "    \"restaurant\": {\n",
      "      \"area\": \"centre\",\n",
      "      \"pricerange\": \"expensive\"\n",
      "    }\n",
      "  },\n",
      "  \"dialogue_id\": \"pmul4398\",\n",
      "  \"metadata\": {\n",
      "    \"domain\": \"restaurant\",\n",
      "    \"state\": {\n",
      "      \"restaurant\": {\n",
      "        \"area\": \"centre\",\n",
      "        \"pricerange\": \"expensive\"\n",
      "      }\n",
      "    },\n",
      "    \"full_state\": {\n",
      "      \"restaurant\": {\n",
      "        \"area\": \"centre\",\n",
      "        \"pricerange\": \"expensive\"\n",
      "      }\n",
      "    },\n",
      "    \"context\": \"Customer: i need a place to dine in the center thats expensive\",\n",
      "    \"response\": \"I have several options for you; do you prefer African, Asian, or British food?\",\n",
      "    \"database\": {\n",
      "      \"restaurant\": 33\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "DOMAINS = ['restaurant', 'hotel', 'attraction', 'train', 'taxi', 'hospital']\n",
    "TOTAL = 50\n",
    "\n",
    "def iterate_dialogues(data, database, context_size=3):\n",
    "    domain_counts = {d: 0 for d in DOMAINS}\n",
    "    \n",
    "    for dialog in data:\n",
    "        # print(dialog)\n",
    "        dialogue_id = dialog['dialogue_id'].split('.')[0].lower()\n",
    "        domain_gt = dialog['services'][0] if len(dialog['services']) > 0 else ''\n",
    "\n",
    "        if domain_gt == '' or domain_gt == 'bus':\n",
    "            continue\n",
    "        \n",
    "        if domain_counts[domain_gt] >= TOTAL:\n",
    "            continue\n",
    "        domain_counts[domain_gt] += 1\n",
    "        \n",
    "        last_state = {}\n",
    "\n",
    "        for tn in range(0, len(dialog['turns']['utterance']), 2):\n",
    "            # 构建上下文\n",
    "            context = [\n",
    "                f\"Customer: {t}\" if i % 2 == 0 else f\"Assistant: {t}\"\n",
    "                for i, t in enumerate(dialog['turns']['utterance'][:tn+1])\n",
    "            ]\n",
    "\n",
    "            # 获取当前轮次对话状态\n",
    "            state = dialog['turns']['frames'][tn]['state']\n",
    "            if not state:\n",
    "                state = {}\n",
    "            else:\n",
    "                state = state[0]['slots_values']\n",
    "                state = {\n",
    "                    k: v[0]\n",
    "                    for k, v in zip(state['slots_values_name'], state['slots_values_list'])\n",
    "                }\n",
    "\n",
    "            # 结构化当前状态\n",
    "            new_state = {}\n",
    "            for sl, val in state.items():\n",
    "                domain, name = sl.split('-')\n",
    "                if domain not in new_state:\n",
    "                    new_state[domain] = {}\n",
    "                new_state[domain][name] = val\n",
    "\n",
    "            # 提取状态更新\n",
    "            state_update = {}\n",
    "            for domain, domain_state in new_state.items():\n",
    "                for slot, value in domain_state.items():\n",
    "                    if slot not in last_state.get(domain, {}) or last_state[domain][slot] != value:\n",
    "                        if domain not in state_update:\n",
    "                            state_update[domain] = {}\n",
    "                        state_update[domain][slot] = value\n",
    "\n",
    "            last_state = new_state\n",
    "\n",
    "            # 数据库查询结果\n",
    "            database_results = {\n",
    "                domain: len(database.query(domain, domain_state))\n",
    "                for domain, domain_state in new_state.items()\n",
    "            }\n",
    "\n",
    "            # 构建 turn 对象\n",
    "            turn = {\n",
    "                'page_content': '\\n'.join(context[-context_size:]),\n",
    "                'question': dialog['turns']['utterance'][tn],\n",
    "                'gt_state': last_state,\n",
    "                'dialogue_id': dialogue_id,\n",
    "                'metadata': {\n",
    "                    'domain': domain_gt,\n",
    "                    'state': state_update,\n",
    "                    'full_state': last_state,\n",
    "                    'context': '\\n'.join(context[-6:]),\n",
    "                    'response': dialog['turns']['utterance'][tn + 1],\n",
    "                    'database': database_results\n",
    "                }\n",
    "            }\n",
    "\n",
    "            yield turn\n",
    "\n",
    "for tn in iterate_dialogues(data, database):\n",
    "    print(json.dumps(tn, indent=2, ensure_ascii=False))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0186691-2eb0-460f-9810-d05436bcacfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/c_w33ry57vj2cnnhqd57w4_40000gn/T/ipykernel_59255/1529181144.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef22df100dc467abfc960da6b071a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cce3d5d3324eaa8c8b2b66bd53bbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478a568b5e1a495c84a9928d7a994d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bc8f6d55354cf8953cbf9ad2c99bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f8b6abf79447a8a3c6321aa714ba20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff3205c3e1d49708e0982f7b2a6e845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75039bf7b8de4878a13cfb479887db21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e237f87c42438a9fd4fd32fe6afe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd467075e3444d79134c0a6a447ba84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005e3fcd3dc24cdbaae5293ab691acb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7876d52e5b4d424da25c5b47feda0a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dialogues: 1914turns [00:14, 131.87turns/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector database has been saved as multiwoz-context-db.vec\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use HuggingFace English model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "docs = []\n",
    "for turn in tqdm(iterate_dialogues(data, database), desc=\"Processing dialogues\", unit=\"turns\"):\n",
    "        doc = Document(page_content=turn['page_content'],\n",
    "                       metadata=turn['metadata'])\n",
    "        docs.append(doc)\n",
    "\n",
    "# Build FAISS vector database\n",
    "faiss_vs = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "\n",
    "# Save to local file\n",
    "with open(\"multiwoz-context-db.vec\", \"wb\") as f:\n",
    "    pickle.dump(faiss_vs, f)\n",
    "\n",
    "print(\"FAISS vector database has been saved as multiwoz-context-db.vec\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecb03b-b44f-406d-a06e-ccc9b6aa8df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "text_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
